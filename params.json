{"name":"How to Build a Bare Metal Switch (BMS) for SDN Labs","tagline":"","body":"The hardware components that make up the BMS are as follows:\r\n\r\n* Magma 13-Slot PCI Expansion Chassis w/ 4 Sun QFE NICs\r\n* Dell Opti-plex GX270 w/ Magma PCI Host Adaptor\r\n\r\nThe Magma expansion chassis allows for the addition of upto 13 quad-port NICs to the Dell Opti-plex GX260 (or any host PC).  Adding extra ports to a PC in itself does not make this a BMS, if that was the case, any PC with two or more Ethernet ports could be called a BMS.  What makes this a BMS is the software.  To make this setup into a real bare-metal switch, I installed Open vSwitch on the host PC. Currently I have two BMS utilizing the above hardware configuration, except my current setup has 12 Sun QFE NICs in each BMS for a total of 48 FastEthernet ports per BMS.\r\n\r\nThe configuration for my BMS is below.\r\n\r\n* Platform: Dell Opti-plex GX270\r\n* Processor(s): (1)x Pentium 4\r\n* OS: Ubuntu Server 14.04 LTS 32-bit\r\n* RAM: 256MB\r\n* Peripheral: MAGMA 13-Slot PCI Expansion Chassis w/ 12 Sun QFE NICs\r\n\r\n**IMPORTANT:**\r\n**FOR THIS CONFIGURATION TO FUNCTION PROPERLY, RAM CANNOT EXCEED 256**\r\n**MB.  OVER 256MB WILL CAUSE BASE ADDRESS REGISTER (BAR) CONFLICTS BETWEEN THE**\r\n**SUN QFE NICS AND THE RAM, AND THE NICS WILL NOT FUNCTION.**\r\n\r\n**If the MAGMA PCI Expansion unit is on during boot, the system will**\r\n**freeze.  You must turn the unit on after system POST and prior to OS bootup.**\r\n**Prevent the OS from booting before you turn the MAGMA unit on by setting the**\r\n**GRUB_TIMEOUT value to -1 and commenting out the GRUB_HIDDEN variables**\r\n**in the /etc/default/grub configuration file.  Update the configuration with**\r\n**command: sudo update-grub**\r\n\r\n### Change the GRUB_TIMEOUT to -1 (infinite)\r\n\r\n_nano /etc/default/grub_\r\n\r\n    GRUB_TIMEOUT=-1\r\n\r\nUpdate the system configuration with the GRUB changes\r\n\r\n    sudo update-grub\r\n\r\n### Specify the name for all network devices using their BUS IDs\r\n\r\n_nano /etc/udev/rules.d/70-persistent-net.rules_\r\n\r\n    KERNELS==”0000:01:0c.0″, SUBSYSTEM==”net”, NAME=”eth0″\r\n\r\n### Configure IP address information on bootup\r\n\r\n_nano /etc/network/interfaces_\r\n\r\n    auto lo\r\n    iface lo inet loopback\r\n    \r\n    #PRIMARY NETWORK\r\n    auto eth0\r\n    iface eth0 inet static\r\n    address 192.168.206.201\r\n    netmask 255.255.255.0\r\n    network 192.168.206.0\r\n    broadcast 192.168.206.255\r\n    gateway 192.168.206.254\r\n    dns-nameservers 192.168.206.254\r\n\r\n### Tune the PC boot-time to skip waiting for network configuration\r\n\r\n_nano /etc/init/failsafe.conf_\r\n\r\nChange this…\r\n\r\n    $PLYMOUTH message –text=”Waiting for network configuration…” || :\r\n    sleep 40\r\n    $PLYMOUTH message –text=”Waiting up to 60 more seconds for network configuration…” || :\r\n    sleep 59\r\n    $PLYMOUTH message –text=”Booting system without full network configuration…” || :\r\n\r\nTo this…\r\n\r\n    $PLYMOUTH message –text=”Waiting for network configuration…” || :\r\n    sleep 1\r\n    $PLYMOUTH message –text=”Waiting up to 60 more seconds for network configuration…” || :\r\n    sleep 1\r\n    $PLYMOUTH message –text=”Booting system without full network configuration…” || :\r\n\r\n### Enable IPv4 forwarding and disable IPv6. \r\n\r\n__nano /etc/sysctl.conf\r\n\r\nUncomment the line\r\n\r\n    net.ipv4.ip_forward=1\r\n\r\nAdd below lines to disable IPv6 configuration (optional)\r\n\r\n    net.ipv6.conf.all.disable_ipv6 = 1\r\n    net.ipv6.conf.default.disable_ipv6 = 1\r\n    net.ipv6.conf.lo.disable_ipv6 = 1\r\n\r\nInstall HTOP system resource monitoring\r\n\r\n    apt-get install htop\r\n\r\nInstall Open vSwitch (OVS)\r\n\r\n    apt-get install openvswitch-common openvswitch-controller openvswitch-dbg openvswitch-ipsec openvswitch-pki openvswitch-switch openvswitch-datapath-source openvswitch-test openvswitch-datapath-dkms\r\n\r\nVerify OVS installation\r\n\r\n    ovs-vsctl show\r\n\r\nInstall User-mode Linux Utilities (uml-utilities) for creation of persistant TAP interfaces used with OVS bridges and other applications\r\n\r\nInstall OpenVPN for the creation of layer 2 VPN tunnels used with OVS to connect real switch ports and other real/virtual nodes\r\n\r\n    apt-get install uml-utilities openvpn\r\n\r\nRestart the computer ensuring the MAGMA is off until the GRUB menu appears !!\r\nOnce the MAGMA is powered on, continue booting the OS.  This must be done\r\nfor every system restart.\r\n\r\n### Enumerate PCI ethernet devices to get BUS ID of all sw ports\r\n\r\n_lspci | grep Ethernet_\r\n\r\n    04:00.1 Ethernet controller: Oracle/SUN Happy Meal 10/100 Ethernet [hme] (rev 01)\r\n    04:01.1 Ethernet controller: Oracle/SUN Happy Meal 10/100 Ethernet [hme] (rev 01)\r\n    04:02.1 Ethernet controller: Oracle/SUN Happy Meal 10/100 Ethernet [hme] (rev 01)\r\n    04:03.1 Ethernet controller: Oracle/SUN Happy Meal 10/100 Ethernet [hme] (rev 01)\r\n    05:00.1 Ethernet controller: Oracle/SUN Happy Meal 10/100 Ethernet [hme] (rev 01)\r\n    05:01.1 Ethernet controller: Oracle/SUN Happy Meal 10/100 Ethernet [hme] (rev 01)\r\n    05:02.1 Ethernet controller: Oracle/SUN Happy Meal 10/100 Ethernet [hme] (rev 01)\r\n    05:03.1 Ethernet controller: Oracle/SUN Happy Meal 10/100 Ethernet [hme] (rev 01)\r\n    and so on....\r\n\r\n### Verify system awareness of network devices\r\n\r\n_find /sys -name net_\r\n\r\n    /sys/devices/pci0000:00/0000:00:1e.0/0000:01:0a.0/0000:02:04.0/0000:03:04.0/0000:04:00.1/net\r\n    /sys/devices/pci0000:00/0000:00:1e.0/0000:01:0a.0/0000:02:04.0/0000:03:04.0/0000:04:01.1/net\r\n    /sys/devices/pci0000:00/0000:00:1e.0/0000:01:0a.0/0000:02:04.0/0000:03:04.0/0000:04:02.1/net\r\n    /sys/devices/pci0000:00/0000:00:1e.0/0000:01:0a.0/0000:02:04.0/0000:03:04.0/0000:04:03.1/net\r\n    /sys/devices/pci0000:00/0000:00:1e.0/0000:01:0a.0/0000:02:04.0/0000:03:05.0/0000:05:00.1/net\r\n    /sys/devices/pci0000:00/0000:00:1e.0/0000:01:0a.0/0000:02:04.0/0000:03:05.0/0000:05:01.1/net\r\n    /sys/devices/pci0000:00/0000:00:1e.0/0000:01:0a.0/0000:02:04.0/0000:03:05.0/0000:05:02.1/net\r\n    /sys/devices/pci0000:00/0000:00:1e.0/0000:01:0a.0/0000:02:04.0/0000:03:05.0/0000:05:03.1/net\r\n    and so on....\r\n\r\nSpecify the name for all network devices using their BUS IDs\r\n\r\n_nano /etc/udev/rules.d/70-persistent-net.rules_\r\n\r\n    KERNELS==”0000:04:00.1″, SUBSYSTEM==”net”, NAME=”port-101″\r\n    KERNELS==”0000:04:01.1″, SUBSYSTEM==”net”, NAME=”port-102″\r\n    KERNELS==”0000:04:02.1″, SUBSYSTEM==”net”, NAME=”port-103″\r\n    KERNELS==”0000:04:03.1″, SUBSYSTEM==”net”, NAME=”port-104″\r\n    KERNELS==”0000:05:00.1″, SUBSYSTEM==”net”, NAME=”port-105″\r\n    KERNELS==”0000:05:01.1″, SUBSYSTEM==”net”, NAME=”port-106″\r\n    KERNELS==”0000:05:02.1″, SUBSYSTEM==”net”, NAME=”port-107″\r\n    KERNELS==”0000:05:03.1″, SUBSYSTEM==”net”, NAME=”port-108″\r\n    and so on....\r\n\r\n### Shutdown and restart system for changes to take effect\r\n\r\n_shutdown -h now_\r\n\r\n### Install Ethtool for port configuration\r\n\r\n_apt-get install ethtool_\r\n\r\nRun below script on the CLI to update the /etc/network/interfaces file with all newly configured ports\r\n\r\n    for i in $(ifconfig -a | grep port | awk ‘{ print  $1 }’); do printf “\\nauto $i \\niface $i inet manual \\n\\t pre-up /sbin/ethtool -s \\$IFACE speed 100 duplex full \\n\\t up ifconfig \\$IFACE 0.0.0.0 up \\n\\t up ip link net \\$IFACE promisc on \\n” >> /etc/network/interfaces;done\r\n\r\nShutdown and restart system for changes to take effect\r\n\r\n_shutdown -h now_\r\n\r\n### Configuration Complete\r\n\r\nAs you can see by the warnings I’ve posted in the above configuration, using an old low-end PC as a BMS may require a few unique tweaks. It took me alot of time researching and applying fixes to overcome the BAR issue noted above. I did create a BMS using a Dell PowerEdge 1850 1u server with 4GB RAM and the only real issue I ran into was that I had to put the Magma PCI Host adaptor into the 1st PCI slot on the server. If I put it in the 2nd PCI slot by mistake, it would cause significant errors. Most of the issues seam to stem from the fact that these old PCs and servers were never intended to host so many PCI bridges (which are found in all the QFE NICs).\r\n\r\nPerformance-wise, the BMS I’ve built can handle alot of lab traffice considering it runs with 256MB RAM and a Pentium4 processor. I’ve linked the BMS to Floodlight as the OFController and everything worked perfectly.\r\n\r\nI hope you found this information helpful, now go build your own BMS and let me know how it turns out!","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}